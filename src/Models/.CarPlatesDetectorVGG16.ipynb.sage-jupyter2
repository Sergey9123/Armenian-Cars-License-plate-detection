{"backend_state":"init","kernel":"py37ml","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":0},"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"CarPlatesDetectorVGG16.ipynb","provenance":[]},"gpuClass":"standard","language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0"}},"trust":false,"type":"settings"}
{"cell_type":"code","exec_count":0,"id":"02094b","input":"test_loss, test_accuracy = model.evaluate(X_test, y_test,steps=int(20))\nprint(\"Test results \\n Loss:\",test_loss,'\\n Accuracy',test_accuracy)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cf5ycZxg3rL7","outputId":"cdc96abb-f957-45d9-c214-940e195025b8"},"output":{"0":{"name":"stdout","output_type":"stream","text":"20/20 [==============================] - 5s 136ms/step - loss: 0.0036 - accuracy: 0.8540\nTest results \n Loss: 0.0036105248145759106 \n Accuracy 0.8539999723434448\n"}},"pos":23,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"6f69ce","input":"","metadata":{"id":"MDBia_4_3rMC"},"pos":37,"type":"cell"}
{"cell_type":"code","exec_count":0,"id":"8c2c99","input":"from scipy.ndimage import interpolation as inter\ndef correct_skew(image, delta=1, limit=5):\n    def determine_score(arr, angle):\n        data = inter.rotate(arr, angle, reshape=False, order=0)\n        histogram = np.sum(data, axis=1)\n        score = np.sum((histogram[1:] - histogram[:-1]) ** 2)\n        return histogram, score\n\n    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1] \n\n    scores = []\n    angles = np.arange(-limit, limit + delta, delta)\n    for angle in angles:\n        histogram, score = determine_score(thresh, angle)\n        scores.append(score)\n\n    best_angle = angles[scores.index(max(scores))]\n\n    (h, w) = image.shape[:2]\n    center = (w // 2, h // 2)\n    M = cv2.getRotationMatrix2D(center, best_angle, 1.0)\n    rotated = cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_CUBIC, \\\n              borderMode=cv2.BORDER_REPLICATE)\n    \n    return best_angle, rotated\n\nfor i_car in range(11,12):\n    img=(X_test[i_car]*255).astype(np.uint8)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    best_angle,corr_im=correct_skew(img, delta=1, limit=25)\n    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n    plt.show()\n    plt.imshow(cv2.cvtColor(corr_im, cv2.COLOR_BGR2RGB))\n    plt.show()","metadata":{"id":"BYAvAOOI3rMB","outputId":"ed05aadf-40da-4e76-da55-64771f3db3dd"},"output":{"0":{"data":{"image/png":"9db788119c0cd53b3444fc4a4c42fb468f0977ad","text/plain":"<Figure size 432x288 with 1 Axes>"},"exec_count":0,"output_type":"execute_result"},"1":{"data":{"image/png":"35e5e8eccc3b74459bb77e8975cbaeb996dfda4b","text/plain":"<Figure size 432x288 with 1 Axes>"},"exec_count":0,"output_type":"execute_result"}},"pos":35,"type":"cell"}
{"cell_type":"code","exec_count":10,"id":"b1dc1d","input":"# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=1)\nX_train, X_val, y_train, y_val = shuffle(X_train, y_train, 3)","metadata":{"id":"KpfOWRJGhEh6"},"pos":14,"type":"cell"}
{"cell_type":"code","exec_count":11,"id":"1db200","input":"logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\ntensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=1)\n\n\nnum_classes=4\n\n\nmodel = Sequential()\nmodel.add(VGG16(weights=\"imagenet\", include_top=False, input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation=\"relu\"))\nmodel.add(Dense(128, activation=\"relu\"))\nmodel.add(Dense(64, activation=\"relu\"))\nmodel.add(Dense(num_classes, activation=\"sigmoid\"))\n\nmodel.layers[-6].trainable = False\n\nmodel.summary()\nmodel.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Frg6Avq3rL3","outputId":"1af290c4-9cca-4e92-b8a1-c934025fd318"},"output":{"0":{"name":"stdout","output_type":"stream","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n                                                                 \n flatten (Flatten)           (None, 25088)             0         \n                                                                 \n dense (Dense)               (None, 128)               3211392   \n                                                                 \n dense_1 (Dense)             (None, 128)               16512     \n                                                                 \n dense_2 (Dense)             (None, 64)                8256      \n                                                                 \n dense_3 (Dense)             (None, 4)                 260       \n                                                                 \n=================================================================\nTotal params: 17,951,108\nTrainable params: 3,236,420\nNon-trainable params: 14,714,688\n_________________________________________________________________\n"}},"pos":16,"type":"cell"}
{"cell_type":"code","exec_count":12,"id":"51b153","input":"train = model.fit(X_train, y_train, validation_data=(X_val, y_val),\n                  epochs=50, batch_size=5,\n                  verbose=1,\n                  callbacks=[tensorboard_callback],)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aSeLLjGo3rL4","outputId":"1499d840-5168-41f2-b407-12ee839e0080"},"output":{"0":{"name":"stdout","output_type":"stream","text":"Epoch 1/50\n464/464 [==============================] - 44s 69ms/step - loss: 0.0086 - accuracy: 0.6675 - val_loss: 0.0054 - val_accuracy: 0.8315\nEpoch 2/50\n464/464 [==============================] - 30s 66ms/step - loss: 0.0042 - accuracy: 0.7876 - val_loss: 0.0041 - val_accuracy: 0.7969\nEpoch 3/50\n464/464 [==============================] - 29s 63ms/step - loss: 0.0030 - accuracy: 0.8519 - val_loss: 0.0044 - val_accuracy: 0.8280\nEpoch 4/50\n464/464 [==============================] - 29s 62ms/step - loss: 0.0022 - accuracy: 0.8774 - val_loss: 0.0039 - val_accuracy: 0.8185\nEpoch 5/50\n464/464 [==============================] - 31s 66ms/step - loss: 0.0020 - accuracy: 0.8877 - val_loss: 0.0036 - val_accuracy: 0.8410\nEpoch 6/50\n464/464 [==============================] - 29s 62ms/step - loss: 0.0015 - accuracy: 0.9007 - val_loss: 0.0048 - val_accuracy: 0.7494\nEpoch 7/50\n464/464 [==============================] - 29s 63ms/step - loss: 0.0014 - accuracy: 0.9016 - val_loss: 0.0035 - val_accuracy: 0.8626\nEpoch 8/50\n464/464 [==============================] - 31s 66ms/step - loss: 0.0012 - accuracy: 0.9106 - val_loss: 0.0038 - val_accuracy: 0.8228\nEpoch 9/50\n464/464 [==============================] - 31s 66ms/step - loss: 0.0011 - accuracy: 0.9171 - val_loss: 0.0049 - val_accuracy: 0.7640\nEpoch 10/50\n464/464 [==============================] - 31s 66ms/step - loss: 0.0011 - accuracy: 0.9115 - val_loss: 0.0035 - val_accuracy: 0.8323\nEpoch 11/50\n464/464 [==============================] - 31s 66ms/step - loss: 9.0553e-04 - accuracy: 0.9270 - val_loss: 0.0048 - val_accuracy: 0.7969\nEpoch 12/50\n464/464 [==============================] - 29s 62ms/step - loss: 8.4065e-04 - accuracy: 0.9154 - val_loss: 0.0035 - val_accuracy: 0.8634\nEpoch 13/50\n464/464 [==============================] - 31s 66ms/step - loss: 8.2485e-04 - accuracy: 0.9223 - val_loss: 0.0031 - val_accuracy: 0.8695\nEpoch 14/50\n464/464 [==============================] - 31s 66ms/step - loss: 7.0188e-04 - accuracy: 0.9279 - val_loss: 0.0035 - val_accuracy: 0.8790\nEpoch 15/50\n464/464 [==============================] - 31s 66ms/step - loss: 0.0014 - accuracy: 0.8946 - val_loss: 0.0034 - val_accuracy: 0.8643\nEpoch 16/50\n464/464 [==============================] - 31s 66ms/step - loss: 7.6662e-04 - accuracy: 0.9288 - val_loss: 0.0031 - val_accuracy: 0.8807\nEpoch 17/50\n464/464 [==============================] - 29s 62ms/step - loss: 5.6446e-04 - accuracy: 0.9460 - val_loss: 0.0030 - val_accuracy: 0.8764\nEpoch 18/50\n464/464 [==============================] - 31s 66ms/step - loss: 4.0303e-04 - accuracy: 0.9396 - val_loss: 0.0030 - val_accuracy: 0.8833\nEpoch 19/50\n464/464 [==============================] - 31s 66ms/step - loss: 3.6567e-04 - accuracy: 0.9491 - val_loss: 0.0033 - val_accuracy: 0.8652\nEpoch 20/50\n464/464 [==============================] - 29s 62ms/step - loss: 4.1919e-04 - accuracy: 0.9413 - val_loss: 0.0033 - val_accuracy: 0.8574\nEpoch 21/50\n464/464 [==============================] - 31s 66ms/step - loss: 4.3675e-04 - accuracy: 0.9460 - val_loss: 0.0031 - val_accuracy: 0.8695\nEpoch 22/50\n464/464 [==============================] - 31s 66ms/step - loss: 5.9941e-04 - accuracy: 0.9378 - val_loss: 0.0034 - val_accuracy: 0.8401\nEpoch 23/50\n464/464 [==============================] - 31s 66ms/step - loss: 9.3923e-04 - accuracy: 0.9201 - val_loss: 0.0035 - val_accuracy: 0.8747\nEpoch 24/50\n464/464 [==============================] - 31s 66ms/step - loss: 4.8171e-04 - accuracy: 0.9426 - val_loss: 0.0030 - val_accuracy: 0.8729\nEpoch 25/50\n464/464 [==============================] - 31s 66ms/step - loss: 3.4006e-04 - accuracy: 0.9495 - val_loss: 0.0029 - val_accuracy: 0.8833\nEpoch 26/50\n464/464 [==============================] - 31s 66ms/step - loss: 2.8997e-04 - accuracy: 0.9577 - val_loss: 0.0032 - val_accuracy: 0.8669\nEpoch 27/50\n464/464 [==============================] - 29s 62ms/step - loss: 2.8261e-04 - accuracy: 0.9594 - val_loss: 0.0029 - val_accuracy: 0.8850\nEpoch 28/50\n464/464 [==============================] - 31s 66ms/step - loss: 2.9165e-04 - accuracy: 0.9590 - val_loss: 0.0030 - val_accuracy: 0.8729\nEpoch 29/50\n464/464 [==============================] - 31s 66ms/step - loss: 2.7630e-04 - accuracy: 0.9529 - val_loss: 0.0028 - val_accuracy: 0.8816\nEpoch 30/50\n464/464 [==============================] - 31s 66ms/step - loss: 2.7617e-04 - accuracy: 0.9577 - val_loss: 0.0030 - val_accuracy: 0.8738\nEpoch 31/50\n464/464 [==============================] - 31s 66ms/step - loss: 5.7110e-04 - accuracy: 0.9426 - val_loss: 0.0030 - val_accuracy: 0.8773\nEpoch 32/50\n464/464 [==============================] - 31s 66ms/step - loss: 3.7960e-04 - accuracy: 0.9456 - val_loss: 0.0029 - val_accuracy: 0.8799\nEpoch 33/50\n464/464 [==============================] - 29s 62ms/step - loss: 2.7688e-04 - accuracy: 0.9607 - val_loss: 0.0029 - val_accuracy: 0.8807\nEpoch 34/50\n464/464 [==============================] - 31s 66ms/step - loss: 2.5462e-04 - accuracy: 0.9568 - val_loss: 0.0034 - val_accuracy: 0.8669\nEpoch 35/50\n464/464 [==============================] - 31s 66ms/step - loss: 3.5722e-04 - accuracy: 0.9521 - val_loss: 0.0031 - val_accuracy: 0.8522\nEpoch 36/50\n464/464 [==============================] - 31s 66ms/step - loss: 6.4707e-04 - accuracy: 0.9495 - val_loss: 0.0031 - val_accuracy: 0.8695\nEpoch 37/50\n464/464 [==============================] - 31s 66ms/step - loss: 4.0240e-04 - accuracy: 0.9482 - val_loss: 0.0032 - val_accuracy: 0.8721\nEpoch 38/50\n464/464 [==============================] - 29s 62ms/step - loss: 2.7643e-04 - accuracy: 0.9573 - val_loss: 0.0029 - val_accuracy: 0.8859\nEpoch 39/50\n464/464 [==============================] - 31s 66ms/step - loss: 1.7769e-04 - accuracy: 0.9689 - val_loss: 0.0029 - val_accuracy: 0.8842\nEpoch 40/50\n464/464 [==============================] - 31s 66ms/step - loss: 1.3757e-04 - accuracy: 0.9676 - val_loss: 0.0030 - val_accuracy: 0.8859\nEpoch 41/50\n464/464 [==============================] - 31s 66ms/step - loss: 1.5462e-04 - accuracy: 0.9685 - val_loss: 0.0030 - val_accuracy: 0.8842\nEpoch 42/50\n464/464 [==============================] - 29s 62ms/step - loss: 2.0482e-04 - accuracy: 0.9659 - val_loss: 0.0029 - val_accuracy: 0.8850\nEpoch 43/50\n464/464 [==============================] - 31s 66ms/step - loss: 2.1364e-04 - accuracy: 0.9603 - val_loss: 0.0029 - val_accuracy: 0.8894\nEpoch 44/50\n464/464 [==============================] - 31s 66ms/step - loss: 2.3333e-04 - accuracy: 0.9598 - val_loss: 0.0029 - val_accuracy: 0.8894\nEpoch 45/50\n464/464 [==============================] - 29s 62ms/step - loss: 2.3608e-04 - accuracy: 0.9663 - val_loss: 0.0029 - val_accuracy: 0.8755\nEpoch 46/50\n464/464 [==============================] - 31s 66ms/step - loss: 1.8708e-04 - accuracy: 0.9590 - val_loss: 0.0030 - val_accuracy: 0.8764\nEpoch 47/50\n464/464 [==============================] - 29s 62ms/step - loss: 1.6229e-04 - accuracy: 0.9655 - val_loss: 0.0028 - val_accuracy: 0.8799\nEpoch 48/50\n464/464 [==============================] - 31s 67ms/step - loss: 1.9571e-04 - accuracy: 0.9633 - val_loss: 0.0035 - val_accuracy: 0.8712\nEpoch 49/50\n464/464 [==============================] - 29s 63ms/step - loss: 2.5439e-04 - accuracy: 0.9680 - val_loss: 0.0029 - val_accuracy: 0.8825\nEpoch 50/50\n464/464 [==============================] - 29s 62ms/step - loss: 1.8157e-04 - accuracy: 0.9659 - val_loss: 0.0030 - val_accuracy: 0.8825\n"}},"pos":18,"type":"cell"}
{"cell_type":"code","exec_count":13,"id":"381da2","input":"scores = model.evaluate(X_test, y_test, verbose=0)\nprint(\"Score : %.2f%%\" % (scores[1]*100))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BmbcZT1d3rL5","outputId":"2560a77f-6272-422a-ab27-9523dad7f30d"},"output":{"0":{"name":"stdout","output_type":"stream","text":"Score : 87.33%\n"}},"pos":20,"type":"cell"}
{"cell_type":"code","exec_count":131,"id":"e9a796","input":"path1 = 'https://mekenan.s3.amazonaws.com/uploads/picture/url/48815/medium_with_watermark_kia-sorento-yerevan-yerevan-4059.jpeg'\ntest_img = io.imread(path1)\ntest_img = cv2.resize(test_img, (IMAGE_SIZE,IMAGE_SIZE))\ntest_img = tf.expand_dims(test_img, axis=0)\nprint(test_img.shape)\ntest_pred = model.predict(test_img)\nprint(test_pred[0])\n\nny1 = test_pred[0]*254\ntest_img = tf.squeeze(test_img).numpy()\ntest_img=(test_img).astype(np.uint8)\nprint(int(ny1[0]))\nimage=test_img\n# image.shape\nimage = cv2.rectangle(image,(int(ny1[0]),int(ny1[1])),(int(ny1[2]),int(ny1[3])),(0, 255, 0))\nplt.title('Test Predicted')\nplt.imshow(image)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":350},"id":"LAS61iNaDpD4","outputId":"a5b75b1b-af24-45db-8bb2-67a7c8caeef8"},"output":{"0":{"name":"stdout","output_type":"stream","text":"(1, 224, 224, 3)\n[0.44835484 0.9996997  0.02294805 0.9972452 ]\n113\n"},"1":{"data":{"text/plain":"<matplotlib.image.AxesImage at 0x7f34a68bf450>"},"exec_count":131,"output_type":"execute_result"},"2":{"data":{"image/png":"00e26d712854d9fae0731e5ce80ed044d1705b27","text/plain":"<Figure size 432x288 with 1 Axes>"},"exec_count":131,"metadata":{"needs_background":"light"},"output_type":"execute_result"}},"pos":26,"type":"cell"}
{"cell_type":"code","exec_count":134,"id":"53522f","input":"plt.figure(figsize=(20,40))\nfor i in range(0,40) :\n    # i = cv2.cvtColor(i,cv2.COLOR_BGR2RGB)\n    plt.subplot(10,5,i+1)\n    plt.axis('off')\n    ny = y_cnn[i]*255\n    image=(X_test[i].copy()*255).astype(np.uint8)\n    image = cv2.rectangle(image,(int(ny[0]),int(ny[1])),(int(ny[2]),int(ny[3])),(0, 255, 0))\n    image =  cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n    plt.title(f\"{i}\")\n    plt.imshow(image)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"DyTT9HQH3rL9","outputId":"1f290147-60d2-4a37-865a-c2b368654de1"},"output":{"0":{"data":{"image/png":"8f712832428d05eb75c005817d75dc26f2521598","text/plain":"<Figure size 1440x2880 with 40 Axes>"},"exec_count":134,"metadata":{"needs_background":"light"},"output_type":"execute_result"}},"pos":27,"type":"cell"}
{"cell_type":"code","exec_count":14,"id":"3d1760","input":"def plot_scores(train) :\n    accuracy = train.history['accuracy']\n    val_accuracy = train.history['val_accuracy']\n    epochs = range(len(accuracy))\n    plt.plot(epochs, accuracy, 'b', label='Score apprentissage')\n    plt.plot(epochs, val_accuracy, 'r', label='Score validation')\n    plt.title('Scores')\n    plt.legend()\n    plt.show()","metadata":{"id":"xKHasPmx3rL6"},"pos":21,"type":"cell"}
{"cell_type":"code","exec_count":141,"id":"55f1e0","input":"img_dir = \"drive/MyDrive/Cars_license_plate_data/Avt/\"\nxml_dir = img_dir\ndata_path = os.path.join(img_dir,'*jpg')\nfiles = glob.glob(data_path)\nprint(len(files))\nfiles.sort()\n\nX_unkown=[]\nfor f in tqdm(files):\n    img = cv2.imread(f)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = cv2.resize(img, (IMAGE_SIZE,IMAGE_SIZE))\n    X_unkown.append(np.array(img))\n\nX_unkown=np.array(X_unkown)\nX_unkown = X_unkown / 255\ny_cnn = model.predict(X_unkown)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ck5zlHED3rL-","outputId":"d8aae50f-022d-4e59-83f4-ec30edf6238f"},"output":{"0":{"name":"stdout","output_type":"stream","text":"5\n"},"1":{"name":"stderr","output_type":"stream","text":"100%|██████████| 5/5 [00:00<00:00, 110.31it/s]\n"}},"pos":30,"type":"cell"}
{"cell_type":"code","exec_count":144,"id":"07bebd","input":"plt.figure(figsize=(20,40))\nfor i in range(0,5) :\n    plt.subplot(10,5,i+1)\n    plt.axis('off')\n    ny = y_cnn[i]*255\n    image=(X_unkown[i].copy()*255).astype(np.uint8)\n    image = cv2.rectangle(image,(int(ny[0]),int(ny[1])),(int(ny[2]),int(ny[3])),(0, 255, 0))\n    plt.imshow(image)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":215},"id":"9AnqOmlj3rL_","outputId":"bc19c4a2-1904-4a76-f7ea-c97f366c5fef"},"output":{"0":{"data":{"image/png":"f27018c9c7d7b19d1fb6f4fbbd6f74241a320cc7","text/plain":"<Figure size 1440x2880 with 5 Axes>"},"exec_count":144,"metadata":{"needs_background":"light"},"output_type":"execute_result"}},"pos":31,"type":"cell"}
{"cell_type":"code","exec_count":15,"id":"14b0db","input":"plot_scores(train)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":281},"id":"NZn-_moE3rL7","outputId":"760c1b05-77bc-4e59-971b-4d6ee5dc4d04"},"output":{"0":{"data":{"image/png":"74ecda4c88def8c366625cafc55ac9b2ba667ae1","text/plain":"<Figure size 432x288 with 1 Axes>"},"exec_count":15,"metadata":{"needs_background":"light"},"output_type":"execute_result"}},"pos":22,"type":"cell"}
{"cell_type":"code","exec_count":16,"id":"ac2551","input":"y_cnn = model.predict(X_test)","metadata":{"id":"jz2nXoEu3rL8"},"pos":25,"type":"cell"}
{"cell_type":"code","exec_count":2,"id":"1f09e9","input":"from google.colab import drive\ndrive.mount('/content/drive')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PMIhrsES5b90","outputId":"2aa8de17-235e-4b48-85ce-72e4e1625e7b"},"output":{"0":{"name":"stdout","output_type":"stream","text":"Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"}},"pos":2,"type":"cell"}
{"cell_type":"code","exec_count":25,"id":"8a0b29","input":"plt.figure(figsize=(15,30))\nimg_index=0\nfor i_car in range(0,20) :\n    plt.subplot(10,5,img_index+1)\n    ny=y_test[i_car]*255\n    image=(X_test[i_car].copy()*255).astype(np.uint8)\n    \n    image=cv2.rectangle(image,(int(ny[0]),int(ny[1])),(int(ny[2]),int(ny[3])),(0, 255, 0))\n    \n    yma,xma,ymi,xmi=int(ny[0]),int(ny[1]),int(ny[2]),int(ny[3])\n    imup=image[xmi:xma,ymi:yma,:]\n    coeff=int(image.shape[0]/(yma-ymi))\n    imup=cv2.resize(image[xmi:xma,ymi:yma,:], (image.shape[0],(xma-xmi)*coeff), interpolation = cv2.INTER_AREA)\n    vertical = np.concatenate((imup, image), axis = 0)\n    plt.imshow(vertical)\n    plt.title(f\"{i_car}\")\n    img_index=img_index+1\nplt.tight_layout()","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":887},"id":"b_1JPgcv3rMA","outputId":"14c6639e-593c-485e-97cf-aad2b35efeb7"},"output":{"0":{"data":{"image/png":"0562c1212b0f94e40e72ab883e5c9e4476e7372f","text/plain":"<Figure size 1080x2160 with 20 Axes>"},"exec_count":25,"metadata":{"needs_background":"light"},"output_type":"execute_result"}},"pos":33,"type":"cell"}
{"cell_type":"code","exec_count":3,"id":"f0d9e7","input":"IMAGE_SIZE = 224\n# old case\nimg_dir = \"drive/MyDrive/Cars_license_plate_data/Unzip_cars_files/\"\nxml_dir = img_dir\n# new case\nimg_dir = \"drive/MyDrive/Cars_license_plate_data/Unzip_cars_files/data/Label_image_800/\"\nxml_dir = \"drive/MyDrive/Cars_license_plate_data/Unzip_cars_files/data/Label_xml_800/\"\ndata_path = os.path.join(img_dir,'*jpg')\nlabels_path=os.path.join(xml_dir,'*xml')\n","metadata":{"id":"YylKffR13rLq"},"pos":5,"type":"cell"}
{"cell_type":"code","exec_count":30,"id":"181273","input":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nfrom tqdm import tqdm\nimport cv2\nimport os\nimport glob\nfrom lxml import etree\nimport random\nfrom skimage import io\n\n\nfrom datetime import datetime\n\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow_hub as hub\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg19 import VGG19\nfrom tensorflow.keras.applications.resnet50 import ResNet50\n\nfrom tensorflow.keras.applications import MobileNetV2, InceptionV3, InceptionResNetV2\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Input\nfrom tensorflow.keras.models import Model\n\nfrom keras.applications.imagenet_utils import preprocess_input","metadata":{"id":"n8rZyIcD3rLd"},"pos":1,"type":"cell"}
{"cell_type":"code","exec_count":38,"id":"90324b","input":"from zipfile import ZipFile\n\nwith ZipFile('drive/MyDrive/Cars_license_plate_data/Cars.zip', 'r') as zipObj:\n   # Extract all the contents of zip file in current directory\n   zipObj.extractall('drive/MyDrive/Cars_license_plate_data/Unzip_cars_files')\n","metadata":{"id":"vuaOCUtkYEhr"},"pos":3,"type":"cell"}
{"cell_type":"code","exec_count":4,"id":"9a26ff","input":"def resize_one_label(f):\n    tree = etree.parse(f)\n    for dim in tree.xpath(\"size\"):\n        width = int(dim.xpath(\"width\")[0].text)\n        height = int(dim.xpath(\"height\")[0].text)\n    for dim in tree.xpath(\"object/bndbox\"):\n        xmin = int(dim.xpath(\"xmin\")[0].text)/(width/IMAGE_SIZE)\n        ymin = int(dim.xpath(\"ymin\")[0].text)/(height/IMAGE_SIZE)\n        xmax = int(dim.xpath(\"xmax\")[0].text)/(width/IMAGE_SIZE)\n        ymax = int(dim.xpath(\"ymax\")[0].text)/(height/IMAGE_SIZE)\n    return [int(xmax), int(ymax), int(xmin), int(ymin)]\n\n\nfiles = glob.glob(data_path)\nfiles.sort()\n#files=random.sample(files, 100)\nX=[]\ny=[]\nfor f in tqdm(files):\n    img = cv2.imread(f)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    # img = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n    # Preprocess images\n    \n    #img_transf = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n    #img_transf[:,:,2] = cv2.equalizeHist(img_transf[:,:,2])\n    #img = cv2.cvtColor(img_transf, cv2.COLOR_HSV2RGB)\n    #########################\n    img = cv2.resize(img, (IMAGE_SIZE,IMAGE_SIZE))\n    img = preprocess_input(img)\n    X.append(np.array(img))\n    # load labels\n    fxml=xml_dir+(os.path.basename(f).split(\"jpg\"))[0]+\"xml\"\n    y.append(resize_one_label(fxml))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bN_0bGgs3rLs","outputId":"ec5510a3-8c62-49c6-bf3b-835962f6a9ea"},"output":{"0":{"name":"stderr","output_type":"stream","text":"100%|██████████| 5209/5209 [01:58<00:00, 43.94it/s]\n"}},"pos":7,"type":"cell"}
{"cell_type":"code","exec_count":43,"id":"d2ad91","input":"plt.figure(figsize=(15,30))\nfor i_car in range(0,20) :\n    plt.subplot(10,5,i_car+1)\n    plt.axis('off')\n    image=X[i_car].copy()\n    image = cv2.rectangle(image,(y[i_car][0],y[i_car][1]),(y[i_car][2],y[i_car][3]),(0, 255, 0),2)\n    plt.title(f\"{i_car}\")\n    plt.imshow(image)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"oqpsmGFv3rLx","outputId":"82877747-a60e-47a3-e6dd-f56645ecd124"},"output":{"0":{"name":"stderr","output_type":"stream","text":"WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nWARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nWARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nWARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nWARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nWARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nWARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nWARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nWARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nWARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nWARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nWARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nWARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nWARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nWARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nWARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nWARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nWARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nWARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\nWARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"},"1":{"data":{"image/png":"1268886e42bf600100d9996d0ad83f89f0a1b05a","text/plain":"<Figure size 1080x2160 with 20 Axes>"},"exec_count":43,"metadata":{"needs_background":"light"},"output_type":"execute_result"}},"pos":10,"type":"cell"}
{"cell_type":"code","exec_count":5,"id":"44b8fd","input":"X=np.array(X)\ny=np.array(y)","metadata":{"id":"iUO7syRm3rLv"},"pos":8,"type":"cell"}
{"cell_type":"code","exec_count":6,"id":"ac69f6","input":"X.shape,y.shape","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tSboiLQ23rLw","outputId":"ca3afd0a-7dce-42d5-9e26-7f8856e2db4c"},"output":{"0":{"data":{"text/plain":"((5209, 224, 224, 3), (5209, 4))"},"exec_count":6,"output_type":"execute_result"}},"pos":9,"type":"cell"}
{"cell_type":"code","exec_count":7,"id":"ace7c5","input":"X = X / 255\ny = y / 255","metadata":{"id":"PLbrl0Ko3rL0"},"pos":12,"type":"cell"}
{"cell_type":"code","exec_count":8,"id":"1fe391","input":"# from sklearn.model_selection import train_test_split\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\ndef shuffle(matrix, target, test_proportion):\n    ratio = int(matrix.shape[0]/test_proportion) #should be int\n    X_train = matrix[ratio:,:]\n    X_test =  matrix[:ratio,:]\n    y_train = target[ratio:,:]\n    y_test =  target[:ratio,:]\n    return X_train, X_test, y_train, y_test\n\nX_train, X_test, y_train, y_test = shuffle(X, y, 3)","metadata":{"id":"BjPqH3i43rL1"},"pos":13,"type":"cell"}
{"cell_type":"markdown","id":"00f247","input":"# Detection","metadata":{"id":"ue-HvLBU3rL8"},"pos":24,"type":"cell"}
{"cell_type":"markdown","id":"11489e","input":"# Normalize!!!\n* coordinates [0,1]\n* colorspace  [0,1]","metadata":{"id":"b5TmKoC-3rLz"},"pos":11,"type":"cell"}
{"cell_type":"markdown","id":"29227e","input":"## Load unknown data\n","metadata":{"id":"maHU3P453rL-"},"pos":29,"type":"cell"}
{"cell_type":"markdown","id":"36ec20","input":"# Load and Prepare data","metadata":{"id":"Pl142Ukd3rLr"},"pos":6,"type":"cell"}
{"cell_type":"markdown","id":"3e33e6","input":"# Constants","metadata":{"id":"nK4DWe0_3rLo"},"pos":4,"type":"cell"}
{"cell_type":"markdown","id":"436383","input":"## What about data quality and orientation?","metadata":{"id":"1caJ6jkl3rMB"},"pos":34,"type":"cell"}
{"cell_type":"markdown","id":"48292b","input":"# Test","metadata":{"id":"SZI-9dtN3rL5"},"pos":19,"type":"cell"}
{"cell_type":"markdown","id":"62ab7e","input":"# Data augmentation\n* https://www.tensorflow.org/tutorials/images/data_augmentation","metadata":{"id":"L0muSMrP3rMC"},"pos":36,"type":"cell"}
{"cell_type":"markdown","id":"888789","input":"# Analyze the problem","metadata":{"id":"XxI0QJgN3rMA"},"pos":32,"type":"cell"}
{"cell_type":"markdown","id":"9e890b","input":"# Detecting Car plates\n* Load images\n* load labels VOC format\n* scaleup \n* train \n* test","metadata":{"id":"qjeivLXn3rLT"},"pos":0,"type":"cell"}
{"cell_type":"markdown","id":"d25aac","input":"# Train model ","metadata":{"id":"Yeahr2ha3rL4"},"pos":17,"type":"cell"}
{"cell_type":"markdown","id":"e6701a","input":"# Build the CNN based on transfer learning technique","metadata":{"id":"Y9NlPD3o3rL2"},"pos":15,"type":"cell"}
{"cell_type":"markdown","id":"f50d5a","input":"# Test on seen data","metadata":{"id":"RmEZzo_h3rL-"},"pos":28,"type":"cell"}
{"id":0,"time":1665670503143,"type":"user"}
{"last_load":1665669965868,"type":"file"}